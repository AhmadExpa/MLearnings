{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "## DTC -> \n",
    "1. Split due to entropy gain\n",
    "2. Class labels are assigned on leaf node\n",
    "3. Slight Change in the data set Changes the whole tree\n",
    "\n",
    "This show \n",
    "1. Sensitivity on input data / training data\n",
    "2. Therefore our model fails to generalize out of sample -> prediction -> but when the input data is change -> prediction will be change\n",
    "How to solve ?\n",
    "making multiple random decision tree -> less Sensitive to training data -> multiple tree -> forest\n",
    "1. multiple dataset from main data -> same number of rows + random sampling and replacing = bootstrapping \n",
    "2. Train DTC on each data set independently \n",
    "3. Use few features to train the data \n",
    "4. the tree which have the most accurate results will be selected\n",
    "\n",
    "categorical classification\n",
    "Aggregation -> Mean /Mode \n",
    "## (bootstrapping+Aggregation) = (bagging)\n",
    "Why is it called random ?\n",
    "bootstrapping+random features selection \n",
    "## Why bootstrapping and features selection ?\n",
    "1. So becomes less Sensitive to training data \n",
    "2. randomizes the relationship b/w tree \n",
    "3. if we don't use random features (all tree will act same and cancel out) which lead to variance \n",
    "same tree will gave the bad prediction (3/3 =1) they will cancel out and balance out\n",
    "\n",
    "## Ideal size of feature subset ?\n",
    " 1. sq.root/ total number of of feature \n",
    " (close to the sq.root / log of total feature)\n",
    "\n",
    "Random forest for regression \n",
    "Aggregation{take the mean at this stage }\n",
    "everything is very similar\n",
    "\n",
    "### Training dataset\n",
    "1. sample 1 -> DTC1 ->\n",
    "2. sample 2 -> DTC2 ->  {VOTING} -> Prediction\n",
    "3. sample 3 -> DTC3 ->\n",
    "\n",
    "{BOOTSTRAPPING}-----{AGGREGATION}   [TESTING DATA]-[Y V/S Prediction]\n",
    "|-----------{BAGGING}-------------|\n",
    "\n",
    "\n",
    "## PROS:\n",
    "\n",
    "1. Robust\n",
    "2. Highly accurate \n",
    "3. Overfitting is not a problem because it takes avg and mode \n",
    "4. classification and regression\n",
    "5. you can also get relative feature |(x=y) link\n",
    "\n",
    "## CONS:\n",
    "\n",
    "1. so many DTC\n",
    "2. so many sub sample\n",
    "3. slow\n",
    "4. computational high \n",
    "5. cost high \n",
    "6. hard to interpret\n",
    "\n",
    "Random forest vs decision tree classification ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
